{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p id=Ahmed.Aly.Gonzalez.ea.2012>[Ahmed et al., 2012] A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J. Smola. Scalable inference in latent variable models. In Proceedings of the fifth ACM international conference on Web search and data mining, 123–132. ACM, 2012.\n",
    "</p>\n",
    "<p id=Aji.McEliece.2000>[Aji & McEliece, 2000] S. M. Aji and R. J. McEliece. The generalized distributive law. IEEE transactions on Information Theory, 46(2):325–343, 2000.\n",
    "</p>\n",
    "<p id=Ba.Kiros.Hinton.2016>[Ba et al., 2016] J. L. Ba, J. R. Kiros, and G. E. Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.\n",
    "</p>\n",
    "<p id=Bahdanau.Cho.Bengio.2014>[Bahdanau et al., 2014] D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.\n",
    "</p>\n",
    "<p id=Bay.Tuytelaars.Van-Gool.2006>[Bay et al., 2006] H. Bay, T. Tuytelaars, and L. Van Gool. Surf: speeded up robust features. In European conference on computer vision, 404–417. Springer, 2006.\n",
    "</p>\n",
    "<p id=Bengio.Ducharme.Vincent.ea.2003>[Bengio et al., 2003] Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin. A neural probabilistic language model. Journal of machine learning research, 3(Feb):1137–1155, 2003.\n",
    "</p>\n",
    "<p id=Bishop.1995>[Bishop, 1995] C. M. Bishop. Training with noise is equivalent to tikhonov regularization. Neural computation, 7(1):108–116, 1995.\n",
    "</p>\n",
    "<p id=Bishop.2006>[Bishop, 2006] C. M. Bishop. Pattern recognition and machine learning. springer, 2006.\n",
    "</p>\n",
    "<p id=Bodla.Singh.Chellappa.ea.2017>[Bodla et al., 2017] N. Bodla, B. Singh, R. Chellappa, and L. S. Davis. Soft-nms–improving object detection with one line of code. In Proceedings of the IEEE international conference on computer vision, 5561–5569. 2017.\n",
    "</p>\n",
    "<p id=Bojanowski.Grave.Joulin.ea.2017>[Bojanowski et al., 2017] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, 5:135–146, 2017.\n",
    "</p>\n",
    "<p id=Bollobas.1999>[Bollobas, 1999] B. Bollobás. Linear analysis. Cambridge University Press, Cambridge, 1999.\n",
    "</p>\n",
    "<p id=Bowman.Angeli.Potts.ea.2015>[Bowman et al., 2015] S. R. Bowman, G. Angeli, C. Potts, and C. D. Manning. A large annotated corpus for learning natural language inference. arXiv preprint arXiv:1508.05326, 2015.\n",
    "</p>\n",
    "<p id=Boyd.Vandenberghe.2004>[Boyd & Vandenberghe, 2004] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, Cambridge, England, 2004.\n",
    "</p>\n",
    "<p id=Brown.Cocke.Della-Pietra.ea.1988>[Brown et al., 1988] P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, R. L. Mercer, and P. Roossin. A statistical approach to language translation. In Coling Budapest 1988 Volume 1: International Conference on Computational Linguistics. 1988.\n",
    "</p>\n",
    "<p id=Brown.Cocke.Della-Pietra.ea.1990>[Brown et al., 1990] P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, J. Lafferty, R. L. Mercer, and P. S. Roossin. A statistical approach to machine translation. Computational linguistics, 16(2):79–85, 1990.\n",
    "</p>\n",
    "<p id=Brown.Sandholm.2017>[Brown & Sandholm, 2017] N. Brown and T. Sandholm. Libratus: the superhuman ai for no-limit poker. In IJCAI, 5226–5228. 2017.\n",
    "</p>\n",
    "<p id=Campbell.Hoane-Jr.Hsu.2002>[Campbell et al., 2002] M. Campbell, A. J. Hoane Jr, and F.-h. Hsu. Deep blue. Artificial intelligence, 134(1-2):57–83, 2002.\n",
    "</p>\n",
    "<p id=Canny.1987>[Canny, 1987] J. Canny. A computational approach to edge detection. In Readings in computer vision, pages 184–203. Elsevier, 1987.\n",
    "</p>\n",
    "<p id=Cer.Diab.Agirre.ea.2017>[Cer et al., 2017] D. Cer, M. Diab, E. Agirre, I. Lopez-Gazpio, and L. Specia. Semeval-2017 task 1: semantic textual similarity multilingual and crosslingual focused evaluation. In Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017), 1–14. 2017.\n",
    "</p>\n",
    "<p id=Cheng.Dong.Lapata.2016>[Cheng et al., 2016] J. Cheng, L. Dong, and M. Lapata. Long short-term memory-networks for machine reading. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, 551–561. 2016.\n",
    "</p>\n",
    "<p id=Cho.Van-Merrienboer.Bahdanau.ea.2014>[Cho et al., 2014a] K. Cho, B. Van Merriënboer, D. Bahdanau, and Y. Bengio. On the properties of neural machine translation: encoder-decoder approaches. arXiv preprint arXiv:1409.1259, 2014.\n",
    "</p>\n",
    "<p id=Cho.Van-Merrienboer.Gulcehre.ea.2014>[Cho et al., 2014b] K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.\n",
    "</p>\n",
    "<p id=Chowdhury.2010>[Chowdhury, 2010] G. G. Chowdhury. Introduction to modern information retrieval. Facet publishing, 2010.\n",
    "</p>\n",
    "<p id=Chung.Gulcehre.Cho.ea.2014>[Chung et al., 2014] J. Chung, C. Gulcehre, K. Cho, and Y. Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.\n",
    "</p>\n",
    "<p id=Collobert.Weston.Bottou.ea.2011>[Collobert et al., 2011] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural language processing (almost) from scratch. Journal of machine learning research, 12(ARTICLE):2493–2537, 2011.\n",
    "</p>\n",
    "<p id=Csiszar.2008>[Csiszar, 2008] I. Csiszár. Axiomatic characterizations of information measures. Entropy, 10(3):261–273, 2008.\n",
    "</p>\n",
    "<p id=Dalal.Triggs.2005>[Dalal & Triggs, 2005] N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. In 2005 IEEE computer society conference on computer vision and pattern recognition (CVPR'05), volume 1, 886–893. IEEE, 2005.\n",
    "</p>\n",
    "<p id=De-Cock.2011>[DeCock, 2011] D. De Cock. Ames, iowa: alternative to the boston housing data as an end of semester regression project. Journal of Statistics Education, 2011.\n",
    "</p>\n",
    "<p id=DeCandia.Hastorun.Jampani.ea.2007>[DeCandia et al., 2007] G. DeCandia, D. Hastorun, M. Jampani, G. Kakulapati, A. Lakshman, A. Pilchin, S. Sivasubramanian, P. Vosshall, and W. Vogels. Dynamo: amazon's highly available key-value store. In ACM SIGOPS operating systems review, volume 41, 205–220. ACM, 2007.\n",
    "</p>\n",
    "<p id=Devlin.Chang.Lee.ea.2018>[Devlin et al., 2018] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\n",
    "</p>\n",
    "<p id=Doersch.Gupta.Efros.2015>[Doersch et al., 2015] C. Doersch, A. Gupta, and A. A. Efros. Unsupervised visual representation learning by context prediction. In Proceedings of the IEEE international conference on computer vision, 1422–1430. 2015.\n",
    "</p>\n",
    "<p id=Dosovitskiy.Beyer.Kolesnikov.ea.2021>[Dosovitskiy et al., 2021] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, and others. An image is worth 16x16 words: transformers for image recognition at scale. In International Conference on Learning Representations. 2021.\n",
    "</p>\n",
    "<p id=Doucet.De-Freitas.Gordon.2001>[Doucet et al., 2001] A. Doucet, N. De Freitas, and N. Gordon. An introduction to sequential monte carlo methods. In Sequential Monte Carlo methods in practice, pages 3–14. Springer, 2001.\n",
    "</p>\n",
    "<p id=Duchi.Hazan.Singer.2011>[Duchi et al., 2011] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12(Jul):2121–2159, 2011.\n",
    "</p>\n",
    "<p id=Dumoulin.Visin.2016>[Dumoulin & Visin, 2016] V. Dumoulin and F. Visin. A guide to convolution arithmetic for deep learning. arXiv preprint arXiv:1603.07285, 2016.\n",
    "</p>\n",
    "<p id=Edelman.Ostrovsky.Schwarz.2007>[Edelman et al., 2007] B. Edelman, M. Ostrovsky, and M. Schwarz. Internet advertising and the generalized second-price auction: selling billions of dollars worth of keywords. American economic review, 97(1):242–259, 2007.\n",
    "</p>\n",
    "<p id=Flammarion.Bach.2015>[Flammarion & Bach, 2015] N. Flammarion and F. Bach. From averaging to acceleration, there is only a step-size. In Conference on Learning Theory, 658–695. 2015.\n",
    "</p>\n",
    "<p id=Gatys.Ecker.Bethge.2016>[Gatys et al., 2016] L. A. Gatys, A. S. Ecker, and M. Bethge. Image style transfer using convolutional neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 2414–2423. 2016.\n",
    "</p>\n",
    "<p id=Ginibre.1965>[Ginibre, 1965] J. Ginibre. Statistical ensembles of complex, quaternion, and real matrices. Journal of Mathematical Physics, 6(3):440–449, 1965.\n",
    "</p>\n",
    "<p id=Girshick.2015>[Girshick, 2015] R. Girshick. Fast r-cnn. In Proceedings of the IEEE international conference on computer vision, 1440–1448. 2015.\n",
    "</p>\n",
    "<p id=Girshick.Donahue.Darrell.ea.2014>[Girshick et al., 2014] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, 580–587. 2014.\n",
    "</p>\n",
    "<p id=Glorot.Bengio.2010>[Glorot & Bengio, 2010] X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the thirteenth international conference on artificial intelligence and statistics, 249–256. 2010.\n",
    "</p>\n",
    "<p id=Goh.2017>[Goh, 2017] G. Goh. Why momentum really works. Distill, 2017. URL: http://distill.pub/2017/momentum, doi:10.23915/distill.00006.\n",
    "</p>\n",
    "<p id=Goldberg.Nichols.Oki.ea.1992>[Goldberg et al., 1992] D. Goldberg, D. Nichols, B. M. Oki, and D. Terry. Using collaborative filtering to weave an information tapestry. Communications of the ACM, 35(12):61–71, 1992.\n",
    "</p>\n",
    "<p id=Goodfellow.Bengio.Courville.2016>[Goodfellow et al., 2016] I. Goodfellow, Y. Bengio, and A. Courville. Deep Learning. MIT Press, 2016. \\url http://www.deeplearningbook.org.\n",
    "</p>\n",
    "<p id=Goodfellow.Pouget-Abadie.Mirza.ea.2014>[Goodfellow et al., 2014] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in neural information processing systems, 2672–2680. 2014.\n",
    "</p>\n",
    "<p id=Gotmare.Keskar.Xiong.ea.2018>[Gotmare et al., 2018] A. Gotmare, N. S. Keskar, C. Xiong, and R. Socher. A closer look at deep learning heuristics: learning rate restarts, warmup and distillation. arXiv preprint arXiv:1810.13243, 2018.\n",
    "</p>\n",
    "<p id=Graves.2013>[Graves, 2013] A. Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850, 2013.\n",
    "</p>\n",
    "<p id=Graves.Schmidhuber.2005>[Graves & Schmidhuber, 2005] A. Graves and J. Schmidhuber. Framewise phoneme classification with bidirectional lstm and other neural network architectures. Neural networks, 18(5-6):602–610, 2005.\n",
    "</p>\n",
    "<p id=Gunawardana.Shani.2015>[Gunawardana & Shani, 2015] A. Gunawardana and G. Shani. Evaluating recommender systems. In Recommender systems handbook, pages 265–308. Springer, 2015.\n",
    "</p>\n",
    "<p id=Guo.Tang.Ye.ea.2017>[Guo et al., 2017] H. Guo, R. Tang, Y. Ye, Z. Li, and X. He. Deepfm: a factorization-machine based neural network for ctr prediction. In Proceedings of the 26th International Joint Conference on Artificial Intelligence, 1725–1731. AAAI Press, 2017.\n",
    "</p>\n",
    "<p id=Hadjis.Zhang.Mitliagkas.ea.2016>[Hadjis et al., 2016] S. Hadjis, C. Zhang, I. Mitliagkas, D. Iter, and C. Ré. Omnivore: an optimizer for multi-device deep learning on cpus and gpus. arXiv preprint arXiv:1606.04487, 2016.\n",
    "</p>\n",
    "<p id=Hazan.Rakhlin.Bartlett.2008>[Hazan et al., 2008] E. Hazan, A. Rakhlin, and P. L. Bartlett. Adaptive online gradient descent. In Advances in Neural Information Processing Systems, 65–72. 2008.\n",
    "</p>\n",
    "<p id=He.Chua.2017>[He & Chua, 2017] X. He and T.-S. Chua. Neural factorization machines for sparse predictive analytics. In Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval, 355–364. ACM, 2017.\n",
    "</p>\n",
    "<p id=He.Gkioxari.Dollar.ea.2017>[He et al., 2017a] K. He, G. Gkioxari, P. Dollár, and R. Girshick. Mask r-cnn. In Proceedings of the IEEE international conference on computer vision, 2961–2969. 2017.\n",
    "</p>\n",
    "<p id=He.Liao.Zhang.ea.2017>[He et al., 2017b] X. He, L. Liao, H. Zhang, L. Nie, X. Hu, and T.-S. Chua. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web, 173–182. International World Wide Web Conferences Steering Committee, 2017.\n",
    "</p>\n",
    "<p id=He.Zhang.Ren.ea.2015>[He et al., 2015] K. He, X. Zhang, S. Ren, and J. Sun. Delving deep into rectifiers: surpassing human-level performance on imagenet classification. In Proceedings of the IEEE international conference on computer vision, 1026–1034. 2015.\n",
    "</p>\n",
    "<p id=He.Zhang.Ren.ea.2016>[He et al., 2016a] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, 770–778. 2016.\n",
    "</p>\n",
    "<p id=He.Zhang.Ren.ea.2016*1>[He et al., 2016b] K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. In European conference on computer vision, 630–645. Springer, 2016.\n",
    "</p>\n",
    "<p id=Hebb.Hebb.1949>[Hebb & Hebb, 1949] D. O. Hebb and D. Hebb. The organization of behavior. Volume 65. Wiley New York, 1949.\n",
    "</p>\n",
    "<p id=Hendrycks.Gimpel.2016>[Hendrycks & Gimpel, 2016] D. Hendrycks and K. Gimpel. Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415, 2016.\n",
    "</p>\n",
    "<p id=Hennessy.Patterson.2011>[Hennessy & Patterson, 2011] J. L. Hennessy and D. A. Patterson. Computer architecture: a quantitative approach. Elsevier, 2011.\n",
    "</p>\n",
    "<p id=Herlocker.Konstan.Borchers.ea.1999>[Herlocker et al., 1999] J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl. An algorithmic framework for performing collaborative filtering. In 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 1999, 230–237. Association for Computing Machinery, Inc, 1999.\n",
    "</p>\n",
    "<p id=Hidasi.Karatzoglou.Baltrunas.ea.2015>[Hidasi et al., 2015] B. Hidasi, A. Karatzoglou, L. Baltrunas, and D. Tikk. Session-based recommendations with recurrent neural networks. arXiv preprint arXiv:1511.06939, 2015.\n",
    "</p>\n",
    "<p id=Hochreiter.Bengio.Frasconi.ea.2001>[Hochreiter et al., 2001] S. Hochreiter, Y. Bengio, P. Frasconi, J. Schmidhuber, and others. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies. 2001.\n",
    "</p>\n",
    "<p id=Hochreiter.Schmidhuber.1997>[Hochreiter & Schmidhuber, 1997] S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780, 1997.\n",
    "</p>\n",
    "<p id=Hoyer.Janzing.Mooij.ea.2009>[Hoyer et al., 2009] P. O. Hoyer, D. Janzing, J. M. Mooij, J. Peters, and B. Schölkopf. Nonlinear causal discovery with additive noise models. In Advances in neural information processing systems, 689–696. 2009.\n",
    "</p>\n",
    "<p id=Hu.Koren.Volinsky.2008>[Hu et al., 2008] Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for implicit feedback datasets. In 2008 Eighth IEEE International Conference on Data Mining, 263–272. Ieee, 2008.\n",
    "</p>\n",
    "<p id=Hu.Lee.Aggarwal.ea.2020>[Hu et al., 2020] Z. Hu, R. K.-W. Lee, C. C. Aggarwal, and A. Zhang. Text style transfer: a review and experimental evaluation. arXiv preprint arXiv:2010.12742, 2020.\n",
    "</p>\n",
    "<p id=Hu.Shen.Sun.2018>[Hu et al., 2018] J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 7132–7141. 2018.\n",
    "</p>\n",
    "<p id=Huang.Liu.Van-Der-Maaten.ea.2017>[Huang et al., 2017] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, 4700–4708. 2017.\n",
    "</p>\n",
    "<p id=Ioffe.2017>[Ioffe, 2017] S. Ioffe. Batch renormalization: towards reducing minibatch dependence in batch-normalized models. In Advances in neural information processing systems, 1945–1953. 2017.\n",
    "</p>\n",
    "<p id=Ioffe.Szegedy.2015>[Ioffe & Szegedy, 2015] S. Ioffe and C. Szegedy. Batch normalization: accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.\n",
    "</p>\n",
    "<p id=Izmailov.Podoprikhin.Garipov.ea.2018>[Izmailov et al., 2018] P. Izmailov, D. Podoprikhin, T. Garipov, D. Vetrov, and A. G. Wilson. Averaging weights leads to wider optima and better generalization. arXiv preprint arXiv:1803.05407, 2018.\n",
    "</p>\n",
    "<p id=Jaeger.2002>[Jaeger, 2002] H. Jaeger. Tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the\" echo state network\" approach. Volume 5. GMD-Forschungszentrum Informationstechnik Bonn, 2002.\n",
    "</p>\n",
    "<p id=James.2007>[James, 2007] W. James. The principles of psychology. Volume 1. Cosimo, Inc., 2007.\n",
    "</p>\n",
    "<p id=Jia.Song.He.ea.2018>[Jia et al., 2018] X. Jia, S. Song, W. He, Y. Wang, H. Rong, F. Zhou, L. Xie, Z. Guo, Y. Yang, L. Yu, and others. Highly scalable deep learning training system with mixed-precision: training imagenet in four minutes. arXiv preprint arXiv:1807.11205, 2018.\n",
    "</p>\n",
    "<p id=Jouppi.Young.Patil.ea.2017>[Jouppi et al., 2017] N. P. Jouppi, C. Young, N. Patil, D. Patterson, G. Agrawal, R. Bajwa, S. Bates, S. Bhatia, N. Boden, A. Borchers, and others. In-datacenter performance analysis of a tensor processing unit. In 2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA), 1–12. IEEE, 2017.\n",
    "</p>\n",
    "<p id=Karras.Aila.Laine.ea.2017>[Karras et al., 2017] T. Karras, T. Aila, S. Laine, and J. Lehtinen. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.\n",
    "</p>\n",
    "<p id=Kim.2014>[Kim, 2014] Y. Kim. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882, 2014.\n",
    "</p>\n",
    "<p id=Kingma.Ba.2014>[Kingma & Ba, 2014] D. P. Kingma and J. Ba. Adam: a method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.\n",
    "</p>\n",
    "<p id=Koller.Friedman.2009>[Koller & Friedman, 2009] D. Koller and N. Friedman. Probabilistic graphical models: principles and techniques. MIT press, 2009.\n",
    "</p>\n",
    "<p id=Kolter.2008>[Kolter, 2008] Z. Kolter. Linear algebra review and reference. Available online: http, 2008.\n",
    "</p>\n",
    "<p id=Koren.2009>[Koren, 2009] Y. Koren. Collaborative filtering with temporal dynamics. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, 447–456. ACM, 2009.\n",
    "</p>\n",
    "<p id=Koren.Bell.Volinsky.2009>[Koren et al., 2009] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems. Computer, pages 30–37, 2009.\n",
    "</p>\n",
    "<p id=Krizhevsky.Sutskever.Hinton.2012>[Krizhevsky et al., 2012] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, 1097–1105. 2012.\n",
    "</p>\n",
    "<p id=Kung.1988>[Kung, 1988] S. Y. Kung. Vlsi array processors. Englewood Cliffs, NJ, Prentice Hall, 1988, 685 p. Research supported by the Semiconductor Research Corp., SDIO, NSF, and US Navy., 1988.\n",
    "</p>\n",
    "<p id=LeCun.Bottou.Bengio.ea.1998>[LeCun et al., 1998] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, and others. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.\n",
    "</p>\n",
    "<p id=Li.2017>[Li, 2017] M. Li. Scaling Distributed Machine Learning with System and Algorithm Co-design. PhD thesis, PhD Thesis, CMU, 2017.\n",
    "</p>\n",
    "<p id=Li.Andersen.Park.ea.2014>[Li et al., 2014] M. Li, D. G. Andersen, J. W. Park, A. J. Smola, A. Ahmed, V. Josifovski, J. Long, E. J. Shekita, and B.-Y. Su. Scaling distributed machine learning with the parameter server. In 11th $\\$USENIX$\\$ Symposium on Operating Systems Design and Implementation ($\\$OSDI$\\$ 14), 583–598. 2014.\n",
    "</p>\n",
    "<p id=Lin.Chen.Yan.2013>[Lin et al., 2013] M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.4400, 2013.\n",
    "</p>\n",
    "<p id=Lin.Feng.Santos.ea.2017>[Lin et al., 2017a] Z. Lin, M. Feng, C. N. d. Santos, M. Yu, B. Xiang, B. Zhou, and Y. Bengio. A structured self-attentive sentence embedding. arXiv preprint arXiv:1703.03130, 2017.\n",
    "</p>\n",
    "<p id=Lin.Goyal.Girshick.ea.2017>[Lin et al., 2017b] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár. Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision, 2980–2988. 2017.\n",
    "</p>\n",
    "<p id=Lin.Lv.Zhu.ea.2010>[Lin et al., 2010] Y. Lin, F. Lv, S. Zhu, M. Yang, T. Cour, K. Yu, L. Cao, Z. Li, M. Tsai, X. Zhou, and others. Imagenet classification: fast descriptor coding and large-scale svm training. Large scale visual recognition challenge, 2010.\n",
    "</p>\n",
    "<p id=Lipton.Steinhardt.2018>[Lipton & Steinhardt, 2018] Z. C. Lipton and J. Steinhardt. Troubling trends in machine learning scholarship. arXiv preprint arXiv:1807.03341, 2018.\n",
    "</p>\n",
    "<p id=Liu.Anguelov.Erhan.ea.2016>[Liu et al., 2016] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and A. C. Berg. Ssd: single shot multibox detector. In European conference on computer vision, 21–37. Springer, 2016.\n",
    "</p>\n",
    "<p id=Liu.Ott.Goyal.ea.2019>[Liu et al., 2019] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov. Roberta: a robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.\n",
    "</p>\n",
    "<p id=Long.Shelhamer.Darrell.2015>[Long et al., 2015] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, 3431–3440. 2015.\n",
    "</p>\n",
    "<p id=Loshchilov.Hutter.2016>[Loshchilov & Hutter, 2016] I. Loshchilov and F. Hutter. Sgdr: stochastic gradient descent with warm restarts. arXiv preprint arXiv:1608.03983, 2016.\n",
    "</p>\n",
    "<p id=Lowe.2004>[Lowe, 2004] D. G. Lowe. Distinctive image features from scale-invariant keypoints. International journal of computer vision, 60(2):91–110, 2004.\n",
    "</p>\n",
    "<p id=Luo.Wang.Shao.ea.2018>[Luo et al., 2018] P. Luo, X. Wang, W. Shao, and Z. Peng. Towards understanding regularization in batch normalization. arXiv preprint, 2018.\n",
    "</p>\n",
    "<p id=Maas.Daly.Pham.ea.2011>[Maas et al., 2011] A. L. Maas, R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng, and C. Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies-volume 1, 142–150. Association for Computational Linguistics, 2011.\n",
    "</p>\n",
    "<p id=McCann.Bradbury.Xiong.ea.2017>[McCann et al., 2017] B. McCann, J. Bradbury, C. Xiong, and R. Socher. Learned in translation: contextualized word vectors. In Advances in Neural Information Processing Systems, 6294–6305. 2017.\n",
    "</p>\n",
    "<p id=McCulloch.Pitts.1943>[McCulloch & Pitts, 1943] W. S. McCulloch and W. Pitts. A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4):115–133, 1943.\n",
    "</p>\n",
    "<p id=McMahan.Holt.Sculley.ea.2013>[McMahan et al., 2013] H. B. McMahan, G. Holt, D. Sculley, M. Young, D. Ebner, J. Grady, L. Nie, T. Phillips, E. Davydov, D. Golovin, and others. Ad click prediction: a view from the trenches. In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, 1222–1230. ACM, 2013.\n",
    "</p>\n",
    "<p id=Merity.Xiong.Bradbury.ea.2016>[Merity et al., 2016] S. Merity, C. Xiong, J. Bradbury, and R. Socher. Pointer sentinel mixture models. arXiv preprint arXiv:1609.07843, 2016.\n",
    "</p>\n",
    "<p id=Mikolov.Chen.Corrado.ea.2013>[Mikolov et al., 2013a] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.\n",
    "</p>\n",
    "<p id=Mikolov.Sutskever.Chen.ea.2013>[Mikolov et al., 2013b] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, 3111–3119. 2013.\n",
    "</p>\n",
    "<p id=Mirhoseini.Pham.Le.ea.2017>[Mirhoseini et al., 2017] A. Mirhoseini, H. Pham, Q. V. Le, B. Steiner, R. Larsen, Y. Zhou, N. Kumar, M. Norouzi, S. Bengio, and J. Dean. Device placement optimization with reinforcement learning. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, 2430–2439. JMLR. org, 2017.\n",
    "</p>\n",
    "<p id=Mnih.Heess.Graves.ea.2014>[Mnih et al., 2014] V. Mnih, N. Heess, A. Graves, and others. Recurrent models of visual attention. In Advances in neural information processing systems, 2204–2212. 2014.\n",
    "</p>\n",
    "<p id=Morey.Hoekstra.Rouder.ea.2016>[Morey et al., 2016] R. D. Morey, R. Hoekstra, J. N. Rouder, M. D. Lee, and E.-J. Wagenmakers. The fallacy of placing confidence in confidence intervals. Psychonomic bulletin & review, 23(1):103–123, 2016.\n",
    "</p>\n",
    "<p id=Nadaraya.1964>[Nadaraya, 1964] E. A. Nadaraya. On estimating regression. Theory of Probability & Its Applications, 9(1):141–142, 1964.\n",
    "</p>\n",
    "<p id=Nesterov.2018>[Nesterov, 2018] Y. Nesterov. Lectures on convex optimization. Volume 137. Springer, 2018.\n",
    "</p>\n",
    "<p id=Nesterov.Vial.2000>[Nesterov & Vial, 2000] Y. Nesterov and J.-P. Vial. Confidence level solutions for stochastic programming, stochastic programming e-print series. 2000.\n",
    "</p>\n",
    "<p id=Neyman.1937>[Neyman, 1937] J. Neyman. Outline of a theory of statistical estimation based on the classical theory of probability. Philosophical Transactions of the Royal Society of London. Series A, Mathematical and Physical Sciences, 236(767):333–380, 1937.\n",
    "</p>\n",
    "<p id=Papineni.Roukos.Ward.ea.2002>[Papineni et al., 2002] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, 311–318. 2002.\n",
    "</p>\n",
    "<p id=Parikh.Tackstrom.Das.ea.2016>[Parikh et al., 2016] A. P. Parikh, O. Täckström, D. Das, and J. Uszkoreit. A decomposable attention model for natural language inference. arXiv preprint arXiv:1606.01933, 2016.\n",
    "</p>\n",
    "<p id=Park.Liu.Wang.ea.2019>[Park et al., 2019] T. Park, M.-Y. Liu, T.-C. Wang, and J.-Y. Zhu. Semantic image synthesis with spatially-adaptive normalization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2337–2346. 2019.\n",
    "</p>\n",
    "<p id=Paulus.Xiong.Socher.2017>[Paulus et al., 2017] R. Paulus, C. Xiong, and R. Socher. A deep reinforced model for abstractive summarization. arXiv preprint arXiv:1705.04304, 2017.\n",
    "</p>\n",
    "<p id=Pennington.Schoenholz.Ganguli.2017>[Pennington et al., 2017] J. Pennington, S. Schoenholz, and S. Ganguli. Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice. In Advances in neural information processing systems, 4785–4795. 2017.\n",
    "</p>\n",
    "<p id=Pennington.Socher.Manning.2014>[Pennington et al., 2014] J. Pennington, R. Socher, and C. Manning. Glove: global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), 1532–1543. 2014.\n",
    "</p>\n",
    "<p id=Peters.Ammar.Bhagavatula.ea.2017>[Peters et al., 2017a] M. Peters, W. Ammar, C. Bhagavatula, and R. Power. Semi-supervised sequence tagging with bidirectional language models. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 1756–1765. 2017.\n",
    "</p>\n",
    "<p id=Peters.Janzing.Scholkopf.2017>[Peters et al., 2017b] J. Peters, D. Janzing, and B. Schölkopf. Elements of causal inference: foundations and learning algorithms. MIT press, 2017.\n",
    "</p>\n",
    "<p id=Peters.Neumann.Iyyer.ea.2018>[Peters et al., 2018] M. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer. Deep contextualized word representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), 2227–2237. 2018.\n",
    "</p>\n",
    "<p id=Petersen.Pedersen.ea.2008>[Petersen et al., 2008] K. B. Petersen, M. S. Pedersen, and others. The matrix cookbook. Technical University of Denmark, 7(15):510, 2008.\n",
    "</p>\n",
    "<p id=Polyak.1964>[Polyak, 1964] B. T. Polyak. Some methods of speeding up the convergence of iteration methods. USSR Computational Mathematics and Mathematical Physics, 4(5):1–17, 1964.\n",
    "</p>\n",
    "<p id=Quadrana.Cremonesi.Jannach.2018>[Quadrana et al., 2018] M. Quadrana, P. Cremonesi, and D. Jannach. Sequence-aware recommender systems. ACM Computing Surveys (CSUR), 51(4):66, 2018.\n",
    "</p>\n",
    "<p id=Radford.Metz.Chintala.2015>[Radford et al., 2015] A. Radford, L. Metz, and S. Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.\n",
    "</p>\n",
    "<p id=Radford.Narasimhan.Salimans.ea.2018>[Radford et al., 2018] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever. Improving language understanding by generative pre-training. OpenAI, 2018.\n",
    "</p>\n",
    "<p id=Radford.Wu.Child.ea.2019>[Radford et al., 2019] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised multitask learners. OpenAI Blog, 1(8):9, 2019.\n",
    "</p>\n",
    "<p id=Rajpurkar.Zhang.Lopyrev.ea.2016>[Rajpurkar et al., 2016] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang. Squad: 100,000+ questions for machine comprehension of text. arXiv preprint arXiv:1606.05250, 2016.\n",
    "</p>\n",
    "<p id=Reddi.Kale.Kumar.2019>[Reddi et al., 2019] S. J. Reddi, S. Kale, and S. Kumar. On the convergence of adam and beyond. arXiv preprint arXiv:1904.09237, 2019.\n",
    "</p>\n",
    "<p id=Redmon.Divvala.Girshick.ea.2016>[Redmon et al., 2016] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, 779–788. 2016.\n",
    "</p>\n",
    "<p id=Reed.De-Freitas.2015>[Reed & DeFreitas, 2015] S. Reed and N. De Freitas. Neural programmer-interpreters. arXiv preprint arXiv:1511.06279, 2015.\n",
    "</p>\n",
    "<p id=Ren.He.Girshick.ea.2015>[Ren et al., 2015] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: towards real-time object detection with region proposal networks. In Advances in neural information processing systems, 91–99. 2015.\n",
    "</p>\n",
    "<p id=Rendle.2010>[Rendle, 2010] S. Rendle. Factorization machines. In 2010 IEEE International Conference on Data Mining, 995–1000. IEEE, 2010.\n",
    "</p>\n",
    "<p id=Rendle.Freudenthaler.Gantner.ea.2009>[Rendle et al., 2009] S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme. Bpr: bayesian personalized ranking from implicit feedback. In Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence, 452–461. AUAI Press, 2009.\n",
    "</p>\n",
    "<p id=Rumelhart.Hinton.Williams.ea.1988>[Rumelhart et al., 1988] D. E. Rumelhart, G. E. Hinton, R. J. Williams, and others. Learning representations by back-propagating errors. Cognitive modeling, 5(3):1, 1988.\n",
    "</p>\n",
    "<p id=Russell.Norvig.2016>[Russell & Norvig, 2016] S. J. Russell and P. Norvig. Artificial intelligence: a modern approach. Malaysia; Pearson Education Limited,, 2016.\n",
    "</p>\n",
    "<p id=Salton.Wong.Yang.1975>[Salton et al., 1975] G. Salton, A. Wong, and C.-S. Yang. A vector space model for automatic indexing. Communications of the ACM, 18(11):613–620, 1975.\n",
    "</p>\n",
    "<p id=Santurkar.Tsipras.Ilyas.ea.2018>[Santurkar et al., 2018] S. Santurkar, D. Tsipras, A. Ilyas, and A. Madry. How does batch normalization help optimization? In Advances in Neural Information Processing Systems, 2483–2493. 2018.\n",
    "</p>\n",
    "<p id=Sarwar.Karypis.Konstan.ea.2001>[Sarwar et al., 2001] B. M. Sarwar, G. Karypis, J. A. Konstan, J. Riedl, and others. Item-based collaborative filtering recommendation algorithms. Www, 1:285–295, 2001.\n",
    "</p>\n",
    "<p id=Schein.Popescul.Ungar.ea.2002>[Schein et al., 2002] A. I. Schein, A. Popescul, L. H. Ungar, and D. M. Pennock. Methods and metrics for cold-start recommendations. In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, 253–260. ACM, 2002.\n",
    "</p>\n",
    "<p id=Schuster.Paliwal.1997>[Schuster & Paliwal, 1997] M. Schuster and K. K. Paliwal. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, 45(11):2673–2681, 1997.\n",
    "</p>\n",
    "<p id=Sedhain.Menon.Sanner.ea.2015>[Sedhain et al., 2015] S. Sedhain, A. K. Menon, S. Sanner, and L. Xie. Autorec: autoencoders meet collaborative filtering. In Proceedings of the 24th International Conference on World Wide Web, 111–112. ACM, 2015.\n",
    "</p>\n",
    "<p id=Sennrich.Haddow.Birch.2015>[Sennrich et al., 2015] R. Sennrich, B. Haddow, and A. Birch. Neural machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909, 2015.\n",
    "</p>\n",
    "<p id=Sergeev.Del-Balso.2018>[Sergeev & DelBalso, 2018] A. Sergeev and M. Del Balso. Horovod: fast and easy distributed deep learning in tensorflow. arXiv preprint arXiv:1802.05799, 2018.\n",
    "</p>\n",
    "<p id=Shannon.1948>[Shannon, 1948] C. E. Shannon. A mathematical theory of communication. The Bell System Technical Journal, 27(3):379–423, 7 1948.\n",
    "</p>\n",
    "<p id=Shao.Yao.Sun.ea.2020>[Shao et al., 2020] H. Shao, S. Yao, D. Sun, A. Zhang, S. Liu, D. Liu, J. Wang, and T. Abdelzaher. Controlvae: controllable variational autoencoder. In Proceedings of the 37th International Conference on Machine Learning. JMLR. org, 2020.\n",
    "</p>\n",
    "<p id=Silver.Huang.Maddison.ea.2016>[Silver et al., 2016] D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, and others. Mastering the game of go with deep neural networks and tree search. nature, 529(7587):484, 2016.\n",
    "</p>\n",
    "<p id=Simonyan.Zisserman.2014>[Simonyan & Zisserman, 2014] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.\n",
    "</p>\n",
    "<p id=Smola.Narayanamurthy.2010>[Smola & Narayanamurthy, 2010] A. Smola and S. Narayanamurthy. An architecture for parallel topic models. Proceedings of the VLDB Endowment, 3(1-2):703–710, 2010.\n",
    "</p>\n",
    "<p id=Srivastava.Hinton.Krizhevsky.ea.2014>[Srivastava et al., 2014] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1):1929–1958, 2014.\n",
    "</p>\n",
    "<p id=Strang.1993>[Strang, 1993] G. Strang. Introduction to linear algebra. Volume 3. Wellesley-Cambridge Press Wellesley, MA, 1993.\n",
    "</p>\n",
    "<p id=Su.Khoshgoftaar.2009>[Su & Khoshgoftaar, 2009] X. Su and T. M. Khoshgoftaar. A survey of collaborative filtering techniques. Advances in artificial intelligence, 2009.\n",
    "</p>\n",
    "<p id=Sukhbaatar.Weston.Fergus.ea.2015>[Sukhbaatar et al., 2015] S. Sukhbaatar, J. Weston, R. Fergus, and others. End-to-end memory networks. In Advances in neural information processing systems, 2440–2448. 2015.\n",
    "</p>\n",
    "<p id=Sutskever.Martens.Dahl.ea.2013>[Sutskever et al., 2013] I. Sutskever, J. Martens, G. Dahl, and G. Hinton. On the importance of initialization and momentum in deep learning. In International conference on machine learning, 1139–1147. 2013.\n",
    "</p>\n",
    "<p id=Sutskever.Vinyals.Le.2014>[Sutskever et al., 2014] I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, 3104–3112. 2014.\n",
    "</p>\n",
    "<p id=Szegedy.Ioffe.Vanhoucke.ea.2017>[Szegedy et al., 2017] C. Szegedy, S. Ioffe, V. Vanhoucke, and A. A. Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. In Thirty-First AAAI Conference on Artificial Intelligence. 2017.\n",
    "</p>\n",
    "<p id=Szegedy.Liu.Jia.ea.2015>[Szegedy et al., 2015] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, 1–9. 2015.\n",
    "</p>\n",
    "<p id=Szegedy.Vanhoucke.Ioffe.ea.2016>[Szegedy et al., 2016] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition, 2818–2826. 2016.\n",
    "</p>\n",
    "<p id=Tallec.Ollivier.2017>[Tallec & Ollivier, 2017] C. Tallec and Y. Ollivier. Unbiasing truncated backpropagation through time. arXiv preprint arXiv:1705.08209, 2017.\n",
    "</p>\n",
    "<p id=Tang.Wang.2018>[Tang & Wang, 2018] J. Tang and K. Wang. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, 565–573. ACM, 2018.\n",
    "</p>\n",
    "<p id=Tay.Dehghani.Bahri.ea.2020>[Tay et al., 2020] Y. Tay, M. Dehghani, D. Bahri, and D. Metzler. Efficient transformers: a survey. arXiv preprint arXiv:2009.06732, 2020.\n",
    "</p>\n",
    "<p id=Teye.Azizpour.Smith.2018>[Teye et al., 2018] M. Teye, H. Azizpour, and K. Smith. Bayesian uncertainty estimation for batch normalized deep networks. arXiv preprint arXiv:1802.06455, 2018.\n",
    "</p>\n",
    "<p id=Tieleman.Hinton.2012>[Tieleman & Hinton, 2012] T. Tieleman and G. Hinton. Lecture 6.5-rmsprop: divide the gradient by a running average of its recent magnitude. COURSERA: Neural networks for machine learning, 4(2):26–31, 2012.\n",
    "</p>\n",
    "<p id=Toscher.Jahrer.Bell.2009>[Toscher et al., 2009] A. Töscher, M. Jahrer, and R. M. Bell. The bigchaos solution to the netflix grand prize. Netflix prize documentation, pages 1–52, 2009.\n",
    "</p>\n",
    "<p id=Treisman.Gelade.1980>[Treisman & Gelade, 1980] A. M. Treisman and G. Gelade. A feature-integration theory of attention. Cognitive psychology, 12(1):97–136, 1980.\n",
    "</p>\n",
    "<p id=Turing.1950>[Turing, 1950] A. Turing. Computing machinery and intelligence. Mind, 59(236):433, 1950.\n",
    "</p>\n",
    "<p id=Uijlings.Van-De-Sande.Gevers.ea.2013>[Uijlings et al., 2013] J. R. Uijlings, K. E. Van De Sande, T. Gevers, and A. W. Smeulders. Selective search for object recognition. International journal of computer vision, 104(2):154–171, 2013.\n",
    "</p>\n",
    "<p id=Van-Loan.Golub.1983>[VanLoan & Golub, 1983] C. F. Van Loan and G. H. Golub. Matrix computations. Johns Hopkins University Press, 1983.\n",
    "</p>\n",
    "<p id=Vaswani.Shazeer.Parmar.ea.2017>[Vaswani et al., 2017] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin. Attention is all you need. In Advances in neural information processing systems, 5998–6008. 2017.\n",
    "</p>\n",
    "<p id=Wang.Davidson.Pan.ea.2016>[Wang et al., 2016] Y. Wang, A. Davidson, Y. Pan, Y. Wu, A. Riffel, and J. D. Owens. Gunrock: a high-performance graph processing library on the gpu. In ACM SIGPLAN Notices, volume 51, 11. ACM, 2016.\n",
    "</p>\n",
    "<p id=Wang.Li.Liberty.ea.2018>[Wang et al., 2018] L. Wang, M. Li, E. Liberty, and A. J. Smola. Optimal message scheduling for aggregation. NETWORKS, 2(3):2–3, 2018.\n",
    "</p>\n",
    "<p id=Warstadt.Singh.Bowman.2019>[Warstadt et al., 2019] A. Warstadt, A. Singh, and S. R. Bowman. Neural network acceptability judgments. Transactions of the Association for Computational Linguistics, 7:625–641, 2019.\n",
    "</p>\n",
    "<p id=Wasserman.2013>[Wasserman, 2013] L. Wasserman. All of statistics: a concise course in statistical inference. Springer Science & Business Media, 2013.\n",
    "</p>\n",
    "<p id=Watkins.Dayan.1992>[Watkins & Dayan, 1992] C. J. Watkins and P. Dayan. Q-learning. Machine learning, 8(3-4):279–292, 1992.\n",
    "</p>\n",
    "<p id=Watson.1964>[Watson, 1964] G. S. Watson. Smooth regression analysis. Sankhyā: The Indian Journal of Statistics, Series A, pages 359–372, 1964.\n",
    "</p>\n",
    "<p id=Welling.Teh.2011>[Welling & Teh, 2011] M. Welling and Y. W. Teh. Bayesian learning via stochastic gradient langevin dynamics. In Proceedings of the 28th international conference on machine learning (ICML-11), 681–688. 2011.\n",
    "</p>\n",
    "<p id=Werbos.1990>[Werbos, 1990] P. J. Werbos. Backpropagation through time: what it does and how to do it. Proceedings of the IEEE, 78(10):1550–1560, 1990.\n",
    "</p>\n",
    "<p id=Wigner.1958>[Wigner, 1958] E. P. Wigner. On the distribution of the roots of certain symmetric matrices. In Ann. Math, 325–327. 1958.\n",
    "</p>\n",
    "<p id=Williams.Waterman.Patterson.2009>[Williams et al., 2009] S. Williams, A. Waterman, and D. Patterson. Roofline: an insightful visual performance model for floating-point programs and multicore architectures. Technical Report, Lawrence Berkeley National Lab.(LBNL), Berkeley, CA (United States), 2009.\n",
    "</p>\n",
    "<p id=Wood.Gasthaus.Archambeau.ea.2011>[Wood et al., 2011] F. Wood, J. Gasthaus, C. Archambeau, L. James, and Y. W. Teh. The sequence memoizer. Communications of the ACM, 54(2):91–98, 2011.\n",
    "</p>\n",
    "<p id=Wu.Ahmed.Beutel.ea.2017>[Wu et al., 2017] C.-Y. Wu, A. Ahmed, A. Beutel, A. J. Smola, and H. Jing. Recurrent recommender networks. In Proceedings of the tenth ACM international conference on web search and data mining, 495–503. ACM, 2017.\n",
    "</p>\n",
    "<p id=Wu.Schuster.Chen.ea.2016>[Wu et al., 2016] Y. Wu, M. Schuster, Z. Chen, Q. V. Le, M. Norouzi, W. Macherey, M. Krikun, Y. Cao, Q. Gao, K. Macherey, and others. Google's neural machine translation system: bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144, 2016.\n",
    "</p>\n",
    "<p id=Xiao.Bahri.Sohl-Dickstein.ea.2018>[Xiao et al., 2018] L. Xiao, Y. Bahri, J. Sohl-Dickstein, S. Schoenholz, and J. Pennington. Dynamical isometry and a mean field theory of cnns: how to train 10,000-layer vanilla convolutional neural networks. In International Conference on Machine Learning, 5393–5402. 2018.\n",
    "</p>\n",
    "<p id=Xiao.Rasul.Vollgraf.2017>[Xiao et al., 2017] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.\n",
    "</p>\n",
    "<p id=Xiong.Wu.Alleva.ea.2018>[Xiong et al., 2018] W. Xiong, L. Wu, F. Alleva, J. Droppo, X. Huang, and A. Stolcke. The microsoft 2017 conversational speech recognition system. In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 5934–5938. IEEE, 2018.\n",
    "</p>\n",
    "<p id=Ye.Yin.Lee.ea.2011>[Ye et al., 2011] M. Ye, P. Yin, W.-C. Lee, and D.-L. Lee. Exploiting geographical influence for collaborative point-of-interest recommendation. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, 325–334. ACM, 2011.\n",
    "</p>\n",
    "<p id=You.Gitman.Ginsburg.2017>[You et al., 2017] Y. You, I. Gitman, and B. Ginsburg. Large batch training of convolutional networks. arXiv preprint arXiv:1708.03888, 2017.\n",
    "</p>\n",
    "<p id=Zaheer.Reddi.Sachan.ea.2018>[Zaheer et al., 2018] M. Zaheer, S. Reddi, D. Sachan, S. Kale, and S. Kumar. Adaptive methods for nonconvex optimization. In Advances in Neural Information Processing Systems, 9793–9803. 2018.\n",
    "</p>\n",
    "<p id=Zeiler.2012>[Zeiler, 2012] M. D. Zeiler. Adadelta: an adaptive learning rate method. arXiv preprint arXiv:1212.5701, 2012.\n",
    "</p>\n",
    "<p id=Zhang.Tay.Zhang.ea.2021>[Zhang et al., 2021] A. Zhang, Y. Tay, S. Zhang, A. Chan, A. T. Luu, S. C. Hui, and J. Fu. Beyond fully-connected layers with quaternions: parameterization of hypercomplex multiplications with 1/n parameters. In International Conference on Learning Representations. 2021.\n",
    "</p>\n",
    "<p id=Zhang.Yao.Sun.ea.2019>[Zhang et al., 2019] S. Zhang, L. Yao, A. Sun, and Y. Tay. Deep learning based recommender system: a survey and new perspectives. ACM Computing Surveys (CSUR), 52(1):5, 2019.\n",
    "</p>\n",
    "<p id=Zhao.Zheng.Xu.ea.2019>[Zhao et al., 2019] Z.-Q. Zhao, P. Zheng, S.-t. Xu, and X. Wu. Object detection with deep learning: a review. IEEE transactions on neural networks and learning systems, 30(11):3212–3232, 2019.\n",
    "</p>\n",
    "<p id=Zhu.Kiros.Zemel.ea.2015>[Zhu et al., 2015] Y. Zhu, R. Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, and S. Fidler. Aligning books and movies: towards story-like visual explanations by watching movies and reading books. In Proceedings of the IEEE international conference on computer vision, 19–27. 2015.\n",
    "</p>\n",
    "<p id=Zhu.Park.Isola.ea.2017>[Zhu et al., 2017] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Proceedings of the IEEE international conference on computer vision, 2223–2232. 2017.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}